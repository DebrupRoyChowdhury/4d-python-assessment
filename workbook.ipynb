{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging \n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'./src')\n",
    "\n",
    "\n",
    "from src.utils.logger import sys_logger\n",
    "\n",
    "os.makedirs(\"./final_data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landing Zone to Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[splitter.py:9]                 Files in landing zone: []\n"
     ]
    }
   ],
   "source": [
    "from src.utils.splitter import split_files\n",
    "\n",
    "split_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging to Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[watermark.py:8]                Reading watermark table from ./watermark.parquet\n",
      "[watermark.py:14]               Watermark table has 21 rows\n",
      "[ingestion.py:12]               Loading customer data\n",
      "[watermark.py:18]               Getting last run date for customer\n",
      "[watermark.py:24]               Last run date for customer is 2024-10-15 00:00:00\n",
      "[files.py:10]                   Getting files to process from ./data/customer/\n",
      "[files.py:14]                   Found 1 files to process\n",
      "[ingestion.py:19]               Processing customer_20241016.csv\n",
      "[files.py:26]                   Reading csv file from ./data/customer/customer_20241016.csv with kwargs {'sep': ','}\n",
      "[dataframes.py:135]             Processing data for customer\n",
      "[files.py:49]                   Getting saved file for customer\n",
      "[files.py:18]                   Getting save filename for customer\n",
      "[files.py:34]                   Reading parquet file from ./final_data/customer.parquet\n",
      "[files.py:56]                   customer file has 12370 rows\n",
      "[dataframes.py:147]             Found 7321 error records for customer\n",
      "[dataframes.py:50]              Processing file with 0 records.\n",
      "[dataframes.py:83]              Detected 6933 old records and 0 new records.\n",
      "[files.py:18]                   Getting save filename for customer\n",
      "[files.py:22]                   Saving file with 12370 rows to ./final_data/customer.parquet\n",
      "[dataframes.py:175]             Processed 0 records for customer\n",
      "[watermark.py:38]               Updating watermark table with {'source': 'customer', 'processed_rows': 0, 'error_rows': 7321, 'process_time': Timestamp('2025-03-15 14:41:42.579439'), 'file_date': Timestamp('2024-10-16 00:00:00'), 'file_id': '656fa7c7-7a3b-4a90-ad37-c86886de3620', 'file_name': 'customer_20241016.csv'}\n",
      "[watermark.py:40]               Watermark table now has 22 rows\n",
      "[files.py:22]                   Saving file with 22 rows to ./watermark.parquet\n",
      "[watermark.py:42]               Watermark table saved to ./watermark.parquet\n",
      "[ingestion.py:25]               Processed customer_20241016.csv\n",
      "[ingestion.py:12]               Loading sales data\n",
      "[watermark.py:18]               Getting last run date for sales\n",
      "[watermark.py:24]               Last run date for sales is 2024-10-15 00:00:00\n",
      "[files.py:10]                   Getting files to process from ./data/sales/\n",
      "[files.py:14]                   Found 1 files to process\n",
      "[ingestion.py:19]               Processing sales_20241016.txt\n",
      "[files.py:26]                   Reading csv file from ./data/sales/sales_20241016.txt with kwargs {'sep': '~', 'names': ['sale_id', 'customer_id', 'product_id', 'quantity', 'price_per_unit', 'total_price', 'sale_date']}\n",
      "[dataframes.py:135]             Processing data for sales\n",
      "[files.py:49]                   Getting saved file for sales\n",
      "[files.py:18]                   Getting save filename for sales\n",
      "[files.py:34]                   Reading parquet file from ./final_data/sales.parquet\n",
      "[files.py:56]                   sales file has 63773 rows\n",
      "[dataframes.py:147]             Found 11395 error records for sales\n",
      "[dataframes.py:50]              Processing file with 0 records.\n",
      "[dataframes.py:113]             Detected 0 changes and 0 new records.\n",
      "[files.py:18]                   Getting save filename for sales\n",
      "[files.py:22]                   Saving file with 63773 rows to ./final_data/sales.parquet\n",
      "[dataframes.py:175]             Processed 0 records for sales\n",
      "[watermark.py:38]               Updating watermark table with {'source': 'sales', 'processed_rows': 0, 'error_rows': 11395, 'process_time': Timestamp('2025-03-15 14:41:42.787159'), 'file_date': Timestamp('2024-10-16 00:00:00'), 'file_id': '2fcdd41f-9cb3-46f7-b860-749659104f84', 'file_name': 'sales_20241016.txt'}\n",
      "[watermark.py:40]               Watermark table now has 23 rows\n",
      "[files.py:22]                   Saving file with 23 rows to ./watermark.parquet\n",
      "[watermark.py:42]               Watermark table saved to ./watermark.parquet\n",
      "[ingestion.py:25]               Processed sales_20241016.txt\n",
      "[ingestion.py:12]               Loading product data\n",
      "[watermark.py:18]               Getting last run date for product\n",
      "[watermark.py:24]               Last run date for product is 2024-10-15 00:00:00\n",
      "[files.py:10]                   Getting files to process from ./data/products/\n",
      "[files.py:14]                   Found 1 files to process\n",
      "[ingestion.py:19]               Processing products_20241016.json\n",
      "[files.py:30]                   Reading json file from ./data/products/products_20241016.json with kwargs {}\n",
      "[dataframes.py:135]             Processing data for product\n",
      "[files.py:49]                   Getting saved file for product\n",
      "[files.py:18]                   Getting save filename for product\n",
      "[files.py:34]                   Reading parquet file from ./final_data/product.parquet\n",
      "[files.py:56]                   product file has 56 rows\n",
      "[dataframes.py:147]             Found 12 error records for product\n",
      "[dataframes.py:50]              Processing file with 0 records.\n",
      "[dataframes.py:83]              Detected 11 old records and 0 new records.\n",
      "[files.py:18]                   Getting save filename for product\n",
      "[files.py:22]                   Saving file with 56 rows to ./final_data/product.parquet\n",
      "[dataframes.py:175]             Processed 0 records for product\n",
      "[watermark.py:38]               Updating watermark table with {'source': 'product', 'processed_rows': 0, 'error_rows': 12, 'process_time': Timestamp('2025-03-15 14:41:42.837894'), 'file_date': Timestamp('2024-10-16 00:00:00'), 'file_id': '9c918739-6933-4b5c-a4e0-052b46839f21', 'file_name': 'products_20241016.json'}\n",
      "[watermark.py:40]               Watermark table now has 24 rows\n",
      "[files.py:22]                   Saving file with 24 rows to ./watermark.parquet\n",
      "[watermark.py:42]               Watermark table saved to ./watermark.parquet\n",
      "[ingestion.py:25]               Processed products_20241016.json\n"
     ]
    }
   ],
   "source": [
    "from src.utils.ingestion import run_ingestion\n",
    "\n",
    "run_ingestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_parquet('./final_data/customer.parquet')\n",
    "\n",
    "dates = customers['effective_from'].unique()\n",
    "\n",
    "data = []\n",
    "for date in sorted(dates):\n",
    "    snapshot = customers[(customers['effective_from'] <= date) & (customers['expiry_date'] > date)]\n",
    "    data.append({'date': date, 'count': len(snapshot)})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.plot(x='date', y='count')\n",
    "plt.title('Customer Growth')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales By Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales By Members\n",
    "customers = pd.read_parquet('./final_data/customer.parquet')\n",
    "\n",
    "dates = customers['effective_from'].unique()\n",
    "sales = pd.read_parquet('./final_data/sales.parquet')\n",
    "merged = sales.merge(customers, on='customer_id', how='outer')\n",
    "merged = merged[(merged['effective_from_y'] <= merged['sale_date']) & (merged['expiry_date_y'] > merged['sale_date'])]\n",
    "data = merged.groupby(['sale_date', 'membership_status'])['total_price'].sum().unstack().fillna(0)\n",
    "\n",
    "data.plot()\n",
    "plt.title('Sales by Membership Status')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Sale Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot of most popular products over time from members vs non-members\n",
    "\n",
    "products = pd.read_parquet('./final_data/product.parquet')\n",
    "customers = pd.read_parquet('./final_data/customer.parquet')\n",
    "sales = pd.read_parquet('./final_data/sales.parquet')\n",
    "\n",
    "merged = sales.merge(customers, on='customer_id', how='outer')\n",
    "merged = merged[(merged['effective_from_y'] <= merged['sale_date']) & (merged['expiry_date_y'] > merged['sale_date'])]\n",
    "merged_with_products = merged.merge(products, on='product_id', how='left')\n",
    "data = merged_with_products.groupby(['sale_date', 'membership_status', 'name'])['total_price'].sum().unstack().fillna(0)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
